{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from keras.datasets import mnist\n",
    "plt.style.use('dark_background')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist SET\n",
      "60000  Features\n",
      "784  Training samples\n"
     ]
    }
   ],
   "source": [
    "##Load Mnist data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train.reshape(X_train.shape[0] , X_train.shape[1]* X_train.shape[2])\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1]* X_test.shape[2])\n",
    "\n",
    "num_features = X_train.shape[0]\n",
    "num_samples = X_train.shape[1]\n",
    "\n",
    "## Normalize data\n",
    "xmax = np.amax(X_train) \n",
    "xmin = np.amin(X_train)\n",
    "X_train = (X_train - xmin)/(xmax - xmin)\n",
    "X_test = (X_test - xmin)/(xmax - xmin)\n",
    "\n",
    "##print\n",
    "print('mnist SET')\n",
    "print(num_features, ' Features')\n",
    "print(num_samples, ' Training samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dimension: 784\n"
     ]
    }
   ],
   "source": [
    "##Parameters for the autoencoder\n",
    "batchsize = 256\n",
    "max_epochs = 50\n",
    "latest_dim = 128\n",
    "hidden_dim = 512\n",
    "learning_rate = 1e-3\n",
    "original_dim = X_train.shape[1] \n",
    "print('Original dimension:', original_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "##convert numpy array to tensor.data.Dataset\n",
    "training_dataset = tf.data.Dataset.from_tensor_slices(X_train).batch(batchsize)\n",
    "testing_dataset = tf.data.Dataset.from_tensor_slices(X_test).batch(batchsize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "## custom layer \n",
    "\n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, hidden_dim, latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_layer = tf.keras.layers.Dense(units=hidden_dim, activation=tf.nn.relu)\n",
    "        self.latent_layer = tf.keras.layers.Dense(units=latent_dim, activation=tf.nn.relu)\n",
    "    \n",
    "    ## method for forward propagation\n",
    "    def call(self, input_features):\n",
    "        activation = self.hidden_layer(input_features)\n",
    "        return self.latent_layer(activation)\n",
    "    \n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, hidden_dim, original_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_layer = tf.keras.layers.Dense(units=hidden_dim, activation=tf.nn.relu)\n",
    "        self.output_layer = tf.keras.layers.Dense(units=original_dim, activation=tf.nn.relu)\n",
    "    ## method for forward propagation\n",
    "    def call(self, encode):\n",
    "        activation = self.hidden_layer(encode)\n",
    "        return self.output_layer(activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "class Autoencoder(tf.keras.Model):\n",
    "    def __init__(self, hidden_dim, latent_dim, original_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = Encoder(hidden_dim, latent_dim)\n",
    "        self.decoder = Decoder(hidden_dim, original_dim)\n",
    "        self.loss = []\n",
    "        \n",
    "    ## method for forward propagation     \n",
    "    def call(self, input_features):\n",
    "        encode = self.encoder(input_features)\n",
    "        reconstructed = self.decoder(encode)\n",
    "        return reconstructed\n",
    "  \n",
    "## build mdel      \n",
    "model = Autoencoder(hidden_dim= hidden_dim, \n",
    "                    latent_dim = latest_dim, \n",
    "                    original_dim = original_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "##loss function\n",
    "def loss(preds, real):\n",
    "    return tf.reduce_mean(tf.square(tf.subtract(preds, real)))\n",
    "\n",
    "##optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "## training\n",
    "def train(loss, model, opt, original):\n",
    "    with tf.GradientTape() as tape:\n",
    "        preds = model(original)\n",
    "        reconstruction_error = loss(preds, original)\n",
    "    gradients = tape.gradient(reconstruction_error, model.trainable_variables)\n",
    "    gradient_variables = zip(gradients, model.trainable_variables)\n",
    "    opt.apply_gradients(gradient_variables)\n",
    "    return reconstruction_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train the network\n",
    "def train_loop(model, opt, loss, dataset, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        for step, batch_features in enumerate(dataset):\n",
    "            loss_values = train(loss, model, opt, batch_features)\n",
    "            epoch_loss += loss_values\n",
    "        #epoch_loss = epoch_loss / batchsize\n",
    "        model.loss.append(epoch_loss)\n",
    "        print('Epoch {}/{}. Loss: {}'.format(epoch + 1, epochs, epoch_loss.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "cannot compute Sub as input #1(zero-based) was expected to be a float tensor but is a double tensor [Op:Sub]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[85], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m## train the autoencoder\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m train_loop(model, optimizer, loss\u001b[38;5;241m=\u001b[39mloss, dataset\u001b[38;5;241m=\u001b[39mtraining_dataset, epochs\u001b[38;5;241m=\u001b[39mmax_epochs)\n",
      "Cell \u001b[1;32mIn[74], line 6\u001b[0m, in \u001b[0;36mtrain_loop\u001b[1;34m(model, opt, loss, dataset, epochs)\u001b[0m\n\u001b[0;32m      4\u001b[0m epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, batch_features \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataset):\n\u001b[1;32m----> 6\u001b[0m     loss_values \u001b[38;5;241m=\u001b[39m train(loss, model, opt, batch_features)\n\u001b[0;32m      7\u001b[0m     epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss_values\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#epoch_loss = epoch_loss / batchsize\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[73], line 5\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(loss, model, opt, original)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[0;32m      4\u001b[0m     preds \u001b[38;5;241m=\u001b[39m model(original)\n\u001b[1;32m----> 5\u001b[0m     reconstruction_error \u001b[38;5;241m=\u001b[39m loss(preds, original)\n\u001b[0;32m      6\u001b[0m gradients \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(reconstruction_error, model\u001b[38;5;241m.\u001b[39mtrainable_variables)\n\u001b[0;32m      7\u001b[0m gradient_variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(gradients, model\u001b[38;5;241m.\u001b[39mtrainable_variables)\n",
      "Cell \u001b[1;32mIn[72], line 3\u001b[0m, in \u001b[0;36mloss\u001b[1;34m(preds, real)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss\u001b[39m(preds, real):\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mreduce_mean(tf\u001b[38;5;241m.\u001b[39msquare(tf\u001b[38;5;241m.\u001b[39msubtract(preds, real)))\n",
      "File \u001b[1;32mc:\\Users\\adity\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\adity\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:7262\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7260\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[0;32m   7261\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 7262\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: cannot compute Sub as input #1(zero-based) was expected to be a float tensor but is a double tensor [Op:Sub]"
     ]
    }
   ],
   "source": [
    "## train the autoencoder\n",
    "\n",
    "train_loop(model, optimizer, loss=loss, dataset=training_dataset, epochs=max_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (50,) and (0,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m##plot loss\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[38;5;28mrange\u001b[39m(max_epochs), model\u001b[38;5;241m.\u001b[39mloss)\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpochs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\adity\\anaconda3\\Lib\\site-packages\\matplotlib\\pyplot.py:2812\u001b[0m, in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2810\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[0;32m   2811\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\u001b[38;5;241m*\u001b[39margs, scalex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, scaley\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m-> 2812\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m gca()\u001b[38;5;241m.\u001b[39mplot(\n\u001b[0;32m   2813\u001b[0m         \u001b[38;5;241m*\u001b[39margs, scalex\u001b[38;5;241m=\u001b[39mscalex, scaley\u001b[38;5;241m=\u001b[39mscaley,\n\u001b[0;32m   2814\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: data} \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\adity\\anaconda3\\Lib\\site-packages\\matplotlib\\axes\\_axes.py:1688\u001b[0m, in \u001b[0;36mAxes.plot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1445\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1446\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[0;32m   1447\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1685\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[0;32m   1686\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1687\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[1;32m-> 1688\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[0;32m   1689\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[0;32m   1690\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[1;32mc:\\Users\\adity\\anaconda3\\Lib\\site-packages\\matplotlib\\axes\\_base.py:311\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[1;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    310\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_plot_args(\n\u001b[0;32m    312\u001b[0m     this, kwargs, ambiguous_fmt_datakey\u001b[38;5;241m=\u001b[39mambiguous_fmt_datakey)\n",
      "File \u001b[1;32mc:\\Users\\adity\\anaconda3\\Lib\\site-packages\\matplotlib\\axes\\_base.py:504\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[1;34m(self, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[0;32m    503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m--> 504\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    505\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    507\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    508\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (50,) and (0,)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##plot loss\n",
    "plt.plot(range(max_epochs), model.loss)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
